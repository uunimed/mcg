<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Analysis & Approval System</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-detection"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }
        
        body {
            background: linear-gradient(135deg, #1a2a6c, #3a7bd5);
            color: #fff;
            min-height: 100vh;
            padding: 20px;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
        }
        
        header {
            text-align: center;
            margin-bottom: 30px;
            padding: 20px;
            background: rgba(0, 0, 0, 0.3);
            border-radius: 15px;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        h1 {
            font-size: 2.8rem;
            margin-bottom: 10px;
            color: #fff;
            text-shadow: 0 2px 5px rgba(0, 0, 0, 0.3);
        }
        
        .subtitle {
            font-size: 1.2rem;
            opacity: 0.9;
            max-width: 800px;
            margin: 0 auto;
            line-height: 1.6;
        }
        
        .main-content {
            display: flex;
            flex-wrap: wrap;
            gap: 30px;
            margin-bottom: 30px;
        }
        
        .video-section {
            flex: 1;
            min-width: 300px;
            background: rgba(0, 0, 0, 0.3);
            border-radius: 15px;
            padding: 20px;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        .video-container {
            position: relative;
            width: 100%;
            background: #000;
            border-radius: 10px;
            overflow: hidden;
            margin-bottom: 20px;
        }
        
        #videoElement {
            width: 100%;
            height: auto;
            display: block;
        }
        
        .video-overlay {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            pointer-events: none;
        }
        
        .face-box {
            position: absolute;
            border: 3px solid;
            border-radius: 8px;
            box-shadow: 0 0 10px rgba(255, 255, 255, 0.5);
        }
        
        .controls {
            display: flex;
            justify-content: center;
            gap: 15px;
            flex-wrap: wrap;
        }
        
        button {
            padding: 12px 25px;
            border: none;
            border-radius: 50px;
            font-size: 1rem;
            font-weight: 600;
            cursor: pointer;
            display: flex;
            align-items: center;
            gap: 8px;
            transition: all 0.3s ease;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2);
        }
        
        #startBtn {
            background: linear-gradient(to right, #00b09b, #96c93d);
            color: white;
        }
        
        #stopBtn {
            background: linear-gradient(to right, #ff416c, #ff4b2b);
            color: white;
        }
        
        button:hover {
            transform: translateY(-3px);
            box-shadow: 0 6px 8px rgba(0, 0, 0, 0.3);
        }
        
        button:active {
            transform: translateY(1px);
        }
        
        button:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none;
        }
        
        .analysis-section {
            flex: 1;
            min-width: 300px;
            background: rgba(0, 0, 0, 0.3);
            border-radius: 15px;
            padding: 20px;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        .status-display {
            text-align: center;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 25px;
            background: rgba(0, 0, 0, 0.2);
            transition: all 0.5s ease;
        }
        
        .status-title {
            font-size: 1.4rem;
            margin-bottom: 10px;
            color: #ccc;
        }
        
        .status-value {
            font-size: 2.5rem;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 2px;
        }
        
        .approved {
            background: rgba(46, 204, 113, 0.3);
            border: 2px solid #2ecc71;
            color: #2ecc71;
        }
        
        .denied {
            background: rgba(231, 76, 60, 0.3);
            border: 2px solid #e74c3c;
            color: #e74c3c;
        }
        
        .pending {
            background: rgba(241, 196, 15, 0.3);
            border: 2px solid #f1c40f;
            color: #f1c40f;
        }
        
        .metrics {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
            margin-bottom: 25px;
        }
        
        .metric-box {
            background: rgba(255, 255, 255, 0.1);
            padding: 15px;
            border-radius: 10px;
            text-align: center;
        }
        
        .metric-value {
            font-size: 1.8rem;
            font-weight: 700;
            margin-bottom: 5px;
        }
        
        .metric-label {
            font-size: 0.9rem;
            opacity: 0.8;
        }
        
        .criteria {
            background: rgba(0, 0, 0, 0.2);
            padding: 20px;
            border-radius: 10px;
        }
        
        .criteria h3 {
            margin-bottom: 15px;
            color: #ddd;
        }
        
        .criteria-list {
            list-style-type: none;
        }
        
        .criteria-list li {
            padding: 8px 0;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
            display: flex;
            justify-content: space-between;
        }
        
        .criteria-list li:last-child {
            border-bottom: none;
        }
        
        .criteria-status {
            font-weight: 600;
        }
        
        .criteria-status.approved {
            color: #2ecc71;
        }
        
        .criteria-status.denied {
            color: #e74c3c;
        }
        
        footer {
            text-align: center;
            padding: 20px;
            margin-top: 20px;
            background: rgba(0, 0, 0, 0.3);
            border-radius: 15px;
            font-size: 0.9rem;
            opacity: 0.8;
        }
        
        .loading {
            display: flex;
            justify-content: center;
            align-items: center;
            height: 300px;
            flex-direction: column;
            gap: 20px;
        }
        
        .spinner {
            border: 5px solid rgba(255, 255, 255, 0.1);
            border-top: 5px solid #3498db;
            border-radius: 50%;
            width: 60px;
            height: 60px;
            animation: spin 1s linear infinite;
        }
        
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        
        @media (max-width: 768px) {
            .main-content {
                flex-direction: column;
            }
            
            h1 {
                font-size: 2.2rem;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1><i class="fas fa-camera"></i> Face Analysis & Approval System</h1>
            <p class="subtitle">This system uses your camera to detect and analyze faces in real-time. It evaluates facial characteristics and provides approval or denial decisions based on configurable criteria.</p>
        </header>
        
        <div class="main-content">
            <div class="video-section">
                <div class="video-container">
                    <video id="videoElement" autoplay playsinline></video>
                    <canvas class="video-overlay" id="overlayCanvas"></canvas>
                </div>
                
                <div class="controls">
                    <button id="startBtn">
                        <i class="fas fa-play"></i> Start Camera
                    </button>
                    <button id="stopBtn" disabled>
                        <i class="fas fa-stop"></i> Stop Camera
                    </button>
                </div>
            </div>
            
            <div class="analysis-section">
                <div class="status-display pending" id="statusDisplay">
                    <div class="status-title">STATUS</div>
                    <div class="status-value" id="statusValue">Pending</div>
                </div>
                
                <div class="metrics">
                    <div class="metric-box">
                        <div class="metric-value" id="faceCount">0</div>
                        <div class="metric-label">Faces Detected</div>
                    </div>
                    <div class="metric-box">
                        <div class="metric-value" id="confidenceLevel">0%</div>
                        <div class="metric-label">Confidence</div>
                    </div>
                    <div class="metric-box">
                        <div class="metric-value" id="processingTime">0ms</div>
                        <div class="metric-label">Processing Time</div>
                    </div>
                </div>
                
                <div class="criteria">
                    <h3>Approval Criteria</h3>
                    <ul class="criteria-list" id="criteriaList">
                        <li>
                            <span>Face clearly visible</span>
                            <span class="criteria-status pending" id="criteria1">Pending</span>
                        </li>
                        <li>
                            <span>Good lighting conditions</span>
                            <span class="criteria-status pending" id="criteria2">Pending</span>
                        </li>
                        <li>
                            <span>Face centered in frame</span>
                            <span class="criteria-status pending" id="criteria3">Pending</span>
                        </li>
                        <li>
                            <span>No excessive movement</span>
                            <span class="criteria-status pending" id="criteria4">Pending</span>
                        </li>
                        <li>
                            <span>Neutral facial expression</span>
                            <span class="criteria-status pending" id="criteria5">Pending</span>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        
        <footer>
            <p>Face Analysis System | Uses TensorFlow.js for face detection | All processing happens locally in your browser</p>
            <p>Note: This is a demonstration. No images or data are transmitted to external servers.</p>
        </footer>
    </div>

    <script>
        // DOM Elements
        const videoElement = document.getElementById('videoElement');
        const overlayCanvas = document.getElementById('overlayCanvas');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const statusDisplay = document.getElementById('statusDisplay');
        const statusValue = document.getElementById('statusValue');
        const faceCount = document.getElementById('faceCount');
        const confidenceLevel = document.getElementById('confidenceLevel');
        const processingTime = document.getElementById('processingTime');
        const criteriaList = document.getElementById('criteriaList');
        
        // Variables
        let stream = null;
        let faceDetector = null;
        let isProcessing = false;
        let animationFrameId = null;
        let lastDetectionTime = 0;
        let detectionHistory = [];
        
        // Initialize face detector
        async function initializeFaceDetector() {
            try {
                // Check if TensorFlow.js is available
                if (!tf || !tf.ready) {
                    throw new Error("TensorFlow.js not loaded properly");
                }
                
                // Initialize the face detector
                const model = faceDetection.SupportedModels.MediaPipeFaceDetector;
                const detectorConfig = {
                    runtime: 'tfjs',
                    maxFaces: 5,
                    modelType: 'short'
                };
                
                faceDetector = await faceDetection.createDetector(model, detectorConfig);
                console.log("Face detector initialized");
                return true;
            } catch (error) {
                console.error("Error initializing face detector:", error);
                alert("Error initializing face detector. Please check console for details.");
                return false;
            }
        }
        
        // Start camera
        async function startCamera() {
            try {
                // Request camera access
                stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { 
                        width: { ideal: 1280 },
                        height: { ideal: 720 },
                        facingMode: 'user'
                    },
                    audio: false 
                });
                
                // Set video source
                videoElement.srcObject = stream;
                
                // Initialize face detector if not already done
                if (!faceDetector) {
                    startBtn.disabled = true;
                    startBtn.innerHTML = '<i class="fas fa-spinner fa-spin"></i> Initializing...';
                    
                    const detectorInitialized = await initializeFaceDetector();
                    
                    startBtn.disabled = false;
                    startBtn.innerHTML = '<i class="fas fa-play"></i> Start Camera';
                    
                    if (!detectorInitialized) {
                        stopCamera();
                        return;
                    }
                }
                
                // Enable/disable buttons
                startBtn.disabled = true;
                stopBtn.disabled = false;
                
                // Set canvas size to match video
                videoElement.onloadedmetadata = () => {
                    overlayCanvas.width = videoElement.videoWidth;
                    overlayCanvas.height = videoElement.videoHeight;
                };
                
                // Start face detection
                isProcessing = true;
                detectFaces();
                
                // Update status
                updateStatus('pending', 'Analyzing...');
            } catch (error) {
                console.error("Error accessing camera:", error);
                alert("Error accessing camera. Please ensure you've granted camera permissions.");
                updateStatus('denied', 'Camera Error');
            }
        }
        
        // Stop camera
        function stopCamera() {
            // Stop face detection
            isProcessing = false;
            
            if (animationFrameId) {
                cancelAnimationFrame(animationFrameId);
                animationFrameId = null;
            }
            
            // Stop video stream
            if (stream) {
                const tracks = stream.getTracks();
                tracks.forEach(track => track.stop());
                stream = null;
                videoElement.srcObject = null;
            }
            
            // Clear canvas
            const ctx = overlayCanvas.getContext('2d');
            ctx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);
            
            // Enable/disable buttons
            startBtn.disabled = false;
            stopBtn.disabled = true;
            
            // Reset UI
            updateStatus('pending', 'Camera Off');
            faceCount.textContent = '0';
            confidenceLevel.textContent = '0%';
            processingTime.textContent = '0ms';
            
            // Reset criteria
            const criteriaItems = document.querySelectorAll('.criteria-status');
            criteriaItems.forEach(item => {
                item.className = 'criteria-status pending';
                item.textContent = 'Pending';
            });
        }
        
        // Detect faces in video stream
        async function detectFaces() {
            if (!isProcessing) return;
            
            const startTime = performance.now();
            
            try {
                // Detect faces
                const faces = await faceDetector.estimateFaces(videoElement, {
                    flipHorizontal: false
                });
                
                const endTime = performance.now();
                const detectTime = Math.round(endTime - startTime);
                
                // Update metrics
                faceCount.textContent = faces.length;
                processingTime.textContent = `${detectTime}ms`;
                
                // Draw face boxes on canvas
                drawFaceBoxes(faces);
                
                // Analyze faces and update status
                analyzeFaces(faces, detectTime);
                
                // Store detection in history (for stability)
                detectionHistory.push({
                    time: Date.now(),
                    faceCount: faces.length
                });
                
                // Keep only last 10 detections
                if (detectionHistory.length > 10) {
                    detectionHistory.shift();
                }
                
            } catch (error) {
                console.error("Error detecting faces:", error);
            }
            
            // Continue detection
            if (isProcessing) {
                animationFrameId = requestAnimationFrame(detectFaces);
            }
        }
        
        // Draw bounding boxes around detected faces
        function drawFaceBoxes(faces) {
            const ctx = overlayCanvas.getContext('2d');
            const width = overlayCanvas.width;
            const height = overlayCanvas.height;
            
            // Clear canvas
            ctx.clearRect(0, 0, width, height);
            
            // Draw each face
            faces.forEach(face => {
                const box = face.box;
                const x = box.xMin * width;
                const y = box.yMin * height;
                const boxWidth = (box.xMax - box.xMin) * width;
                const boxHeight = (box.yMax - box.yMin) * height;
                
                // Determine box color based on confidence
                const confidence = face.score || 0;
                let color;
                
                if (confidence > 0.9) {
                    color = '#2ecc71'; // Green for high confidence
                } else if (confidence > 0.7) {
                    color = '#f1c40f'; // Yellow for medium confidence
                } else {
                    color = '#e74c3c'; // Red for low confidence
                }
                
                // Draw bounding box
                ctx.strokeStyle = color;
                ctx.lineWidth = 3;
                ctx.strokeRect(x, y, boxWidth, boxHeight);
                
                // Draw confidence label
                ctx.fillStyle = color;
                ctx.font = 'bold 16px Arial';
                ctx.fillText(
                    `${(confidence * 100).toFixed(1)}%`, 
                    x + 5, 
                    y - 10
                );
            });
        }
        
        // Analyze detected faces and update approval status
        function analyzeFaces(faces, detectTime) {
            if (faces.length === 0) {
                updateStatus('denied', 'No Face Detected');
                updateCriteria([false, false, false, false, false]);
                confidenceLevel.textContent = '0%';
                return;
            }
            
            // For simplicity, we'll analyze the first (largest) face
            const primaryFace = faces.reduce((prev, current) => {
                const prevArea = (prev.box.xMax - prev.box.xMin) * (prev.box.yMax - prev.box.yMin);
                const currentArea = (current.box.xMax - current.box.xMin) * (current.box.yMax - current.box.yMin);
                return (currentArea > prevArea) ? current : prev;
            });
            
            // Calculate confidence
            const confidence = primaryFace.score || 0;
            confidenceLevel.textContent = `${(confidence * 100).toFixed(1)}%`;
            
            // Calculate face position in frame
            const width = overlayCanvas.width;
            const height = overlayCanvas.height;
            const faceX = (primaryFace.box.xMin + primaryFace.box.xMax) / 2 * width;
            const faceY = (primaryFace.box.yMin + primaryFace.box.yMax) / 2 * height;
            const faceWidth = (primaryFace.box.xMax - primaryFace.box.xMin) * width;
            const faceHeight = (primaryFace.box.yMax - primaryFace.box.yMin) * height;
            
            // Evaluate criteria
            const criteria = evaluateFaceCriteria(primaryFace, faceX, faceY, faceWidth, faceHeight, width, height, confidence);
            
            // Update criteria display
            updateCriteria(criteria);
            
            // Determine overall status
            const allApproved = criteria.every(c => c === true);
            const someDenied = criteria.some(c => c === false);
            
            if (allApproved) {
                updateStatus('approved', 'Approved');
            } else if (someDenied) {
                updateStatus('denied', 'Denied');
            } else {
                updateStatus('pending', 'Analyzing...');
            }
        }
        
        // Evaluate face against approval criteria
        function evaluateFaceCriteria(face, x, y, width, height, frameWidth, frameHeight, confidence) {
            // Criterion 1: Face clearly visible (confidence > 0.7)
            const criterion1 = confidence > 0.7;
            
            // Criterion 2: Good lighting conditions (estimated by face size and confidence)
            // In a real system, this would analyze image brightness/contrast
            const criterion2 = confidence > 0.65 && (width * height) > (frameWidth * frameHeight * 0.05);
            
            // Criterion 3: Face centered in frame (within 40% of center)
            const centerX = frameWidth / 2;
            const centerY = frameHeight / 2;
            const xOffset = Math.abs(x - centerX) / centerX;
            const yOffset = Math.abs(y - centerY) / centerY;
            const criterion3 = xOffset < 0.4 && yOffset < 0.4;
            
            // Criterion 4: No excessive movement (check detection history)
            let criterion4 = true;
            if (detectionHistory.length >= 5) {
                const recentFaces = detectionHistory.slice(-5);
                const faceCountChanges = recentFaces.filter((detection, index, arr) => {
                    return index > 0 && Math.abs(detection.faceCount - arr[index-1].faceCount) > 1;
                }).length;
                criterion4 = faceCountChanges < 2;
            }
            
            // Criterion 5: Neutral facial expression
            // In a real system, this would analyze facial landmarks
            // For this demo, we'll simulate based on face proportion
            const faceRatio = width / height;
            const criterion5 = faceRatio > 0.7 && faceRatio < 1.3;
            
            return [criterion1, criterion2, criterion3, criterion4, criterion5];
        }
        
        // Update criteria display
        function updateCriteria(criteria) {
            criteria.forEach((criterion, index) => {
                const element = document.getElementById(`criteria${index + 1}`);
                if (criterion) {
                    element.className = 'criteria-status approved';
                    element.textContent = 'Approved';
                } else {
                    element.className = 'criteria-status denied';
                    element.textContent = 'Denied';
                }
            });
        }
        
        // Update status display
        function updateStatus(status, text) {
            // Remove all status classes
            statusDisplay.classList.remove('approved', 'denied', 'pending');
            
            // Add new status class
            statusDisplay.classList.add(status);
            
            // Update text
            statusValue.textContent = text;
        }
        
        // Event Listeners
        startBtn.addEventListener('click', startCamera);
        stopBtn.addEventListener('click', stopCamera);
        
        // Initialize app
        document.addEventListener('DOMContentLoaded', () => {
            // Set initial status
            updateStatus('pending', 'Ready to Start');
            
            // Try to initialize the face detector early (in background)
            setTimeout(() => {
                initializeFaceDetector().then(success => {
                    if (success) {
                        console.log("Face detector ready");
                    }
                });
            }, 500);
        });
        
        // Handle page visibility changes
        document.addEventListener('visibilitychange', () => {
            if (document.hidden && isProcessing) {
                // Page is hidden, stop camera to save resources
                stopCamera();
            }
        });
    </script>
</body>
</html>
